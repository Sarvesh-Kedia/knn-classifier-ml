{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('cat4.csv')\n",
    "\n",
    "\n",
    "# print(data.head())\n",
    "\n",
    "\n",
    "#features\n",
    "x = data.drop(['index', 'galex_objid', 'sdss_objid', 'class', 'spectrometric_redshift', 'pred'], axis = 1) \n",
    "# print(x.head())\n",
    "\n",
    "\n",
    "#class\n",
    "y = data['class']\n",
    "\n",
    "redshift = data['spectrometric_redshift']\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "#fix scientifci notations to normal floats\n",
    "# def scitofloat(x):\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     u    g    r    i    z  extinction_u  extinction_g  extinction_r  \\\n",
      "0  1.0  1.0  1.0  1.0  1.0      0.518859      0.514697      0.510169   \n",
      "1  1.0  1.0  1.0  1.0  1.0      0.520498      0.515976      0.511054   \n",
      "2  1.0  1.0  1.0  1.0  1.0      0.520396      0.515896      0.510999   \n",
      "3  1.0  1.0  1.0  1.0  1.0      0.520920      0.516305      0.511282   \n",
      "4  1.0  1.0  1.0  1.0  1.0      0.520923      0.516307      0.511283   \n",
      "\n",
      "   extinction_i  extinction_z  ...       u-g       u-r       u-i       u-z  \\\n",
      "0      0.507557      0.505621  ...  0.563752  0.639445  0.699413  0.633595   \n",
      "1      0.508215      0.506111  ...  0.511422  0.494797  0.532386  0.563918   \n",
      "2      0.508174      0.506080  ...  0.627986  0.682746  0.648898  0.701978   \n",
      "3      0.508384      0.506237  ...  0.582493  0.647692  0.726401  0.764159   \n",
      "4      0.508385      0.506237  ...  0.506167  0.463440  0.414806  0.390012   \n",
      "\n",
      "        g-r       g-i       g-z       r-i       r-z       i-z  \n",
      "0  0.578484  0.642929  0.572306  0.567473  0.493679  0.426332  \n",
      "1  0.483379  0.520995  0.552650  0.537563  0.569029  0.531795  \n",
      "2  0.560411  0.522637  0.582525  0.462017  0.522564  0.560340  \n",
      "3  0.568539  0.655526  0.699012  0.590861  0.638003  0.549631  \n",
      "4  0.457311  0.408831  0.384160  0.450753  0.425372  0.474241  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#normalise the values of x\n",
    "\n",
    "outercnt = 0\n",
    "for index, row in x.iterrows():\n",
    "    innercnt = 0\n",
    "    for column in x:\n",
    "#         x.at[outercnt, column] = scitofloat(x.iloc[outercnt, innercnt])\n",
    "        x.at[outercnt, column] = sigmoid(x.iloc[outercnt, innercnt])\n",
    "#         print(outercnt, column, '\\t\\t', x.iloc[outercnt, innercnt])\n",
    "        innercnt += 1\n",
    "    outercnt += 1    \n",
    "\n",
    "#     print('\\n\\n')\n",
    "\n",
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_dataset(data, verbose=True):\n",
    "    label1, label2 = 0, 0\n",
    "    data_size = len(data)\n",
    "    for index, row in data.iterrows():\n",
    "        label = row['class']\n",
    "#         print(label)\n",
    "        if label == 1:\n",
    "            label1 += 1\n",
    "        else:\n",
    "            label2 += 1\n",
    "    if verbose:\n",
    "        print('Total of samples: %d' % data_size)\n",
    "        print('Total label 1: %d' % label1)\n",
    "        print('Total label 0: %d' % label2)\n",
    "    return [len(data), label1, label2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of samples: 33463\n",
      "Total label 1: 23389\n",
      "Total label 0: 10074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33463, 23389, 10074]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.6\n",
    "_, label1, label2 = info_dataset(data,False)\n",
    "\n",
    "info_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         u    g    r    i    z  extinction_u  extinction_g  extinction_r  \\\n",
      "17141  1.0  1.0  1.0  1.0  1.0      0.563760      0.549788      0.534503   \n",
      "31720  1.0  1.0  1.0  1.0  1.0      0.513283      0.510351      0.507161   \n",
      "30303  1.0  1.0  1.0  1.0  1.0      0.512217      0.509520      0.506586   \n",
      "25396  1.0  1.0  1.0  1.0  1.0      0.531213      0.524334      0.516841   \n",
      "\n",
      "       extinction_i  extinction_z  ...       u-r       u-i       u-z  \\\n",
      "17141      0.525657      0.519092  ...  0.582326  0.564625  0.525910   \n",
      "31720      0.505322      0.503959  ...  0.438573  0.473958  0.515487   \n",
      "30303      0.504895      0.503641  ...  0.622254  0.627557  0.692209   \n",
      "25396      0.512517      0.509311  ...  0.702868  0.761691  0.794556   \n",
      "\n",
      "            g-r       g-i       g-z       r-i       r-z       i-z  class  \n",
      "17141  0.569140  0.551310  0.512433  0.481914  0.443098  0.461023      1  \n",
      "31720  0.466001  0.501621  0.543072  0.535612  0.576623  0.541463      1  \n",
      "30303  0.500226  0.505882  0.577434  0.505656  0.577213  0.571683      1  \n",
      "25396  0.536222  0.609717  0.654021  0.574682  0.620488  0.547516      1  \n",
      "\n",
      "[4 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "#get training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 15)\n",
    "\n",
    "train_set = pd.concat([xTrain, yTrain], axis=1, sort=False)\n",
    "test_set = pd.concat([xTest, yTest], axis=1, sort=False)\n",
    "\n",
    "\n",
    "print(train_set.iloc[0:4])\n",
    "# print(train_set.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(p1, p2):\n",
    "    dim, sum_ = len(p1), 0\n",
    "    for index in range(dim - 1):\n",
    "        sum_ += math.pow(p1[index] - p2[index], 2)\n",
    "    return math.sqrt(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_set, new_sample, K):\n",
    "\n",
    "#     print('train set', train_set, type(train_set))\n",
    "#     print('new sample', new_sample, type(new_sample))\n",
    "    dists, train_size = {}, len(train_set)\n",
    "\n",
    "    for i in range(train_size):\n",
    "#         print(train_set.iloc[i-1].values.tolist())\n",
    "#         print(new_sample.values.tolist()[0])\n",
    "#         print('\\n\\n')\n",
    "        d = euclidian_dist(train_set.iloc[i-1].values.tolist(), new_sample.values.tolist()[0])\n",
    "        dists[i] = d\n",
    "        \n",
    "#     print('done')\n",
    "    \n",
    "    k_neighbors = sorted(dists, key=dists.get)[:K]\n",
    "    \n",
    "    qty_label1, qty_label2 = 0, 0\n",
    "    \n",
    "    for index in k_neighbors:\n",
    "#         print('index, ', index)\n",
    "#         print(train_set.iloc[index])\n",
    "        \n",
    "    \n",
    "        #fix this\n",
    "        if train_set.iloc[index].values.tolist()[-1] == 1:\n",
    "            qty_label1 += 1\n",
    "        else:\n",
    "            qty_label2 += 1\n",
    "        \n",
    "            \n",
    "    if qty_label1 > qty_label2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "predicted, actual 1 1.0\n",
      "1\n",
      "predicted, actual 1 0.0\n",
      "2\n",
      "predicted, actual 1 1.0\n",
      "3\n",
      "predicted, actual 1 1.0\n",
      "4\n",
      "predicted, actual 1 1.0\n",
      "5\n",
      "predicted, actual 1 1.0\n",
      "6\n",
      "predicted, actual 1 1.0\n",
      "7\n",
      "predicted, actual 1 0.0\n",
      "8\n",
      "predicted, actual 1 1.0\n",
      "9\n",
      "predicted, actual 1 1.0\n",
      "10\n",
      "predicted, actual 1 0.0\n",
      "11\n",
      "predicted, actual 1 1.0\n",
      "12\n",
      "predicted, actual 1 1.0\n",
      "13\n",
      "predicted, actual 1 1.0\n",
      "14\n",
      "predicted, actual 1 1.0\n",
      "15\n",
      "predicted, actual 1 1.0\n",
      "16\n",
      "predicted, actual 1 1.0\n",
      "17\n",
      "predicted, actual 1 1.0\n",
      "18\n",
      "predicted, actual 1 1.0\n",
      "19\n",
      "predicted, actual 1 1.0\n",
      "20\n",
      "predicted, actual 1 1.0\n",
      "21\n",
      "predicted, actual 1 1.0\n",
      "22\n",
      "predicted, actual 1 1.0\n",
      "23\n",
      "predicted, actual 0 0.0\n",
      "24\n",
      "predicted, actual 0 1.0\n",
      "25\n",
      "predicted, actual 1 1.0\n",
      "26\n",
      "predicted, actual 1 1.0\n",
      "27\n",
      "predicted, actual 1 0.0\n",
      "28\n",
      "predicted, actual 1 0.0\n",
      "29\n",
      "predicted, actual 1 0.0\n",
      "30\n",
      "predicted, actual 1 1.0\n",
      "31\n",
      "predicted, actual 0 0.0\n",
      "32\n",
      "predicted, actual 1 1.0\n",
      "33\n",
      "predicted, actual 1 1.0\n",
      "34\n",
      "predicted, actual 1 1.0\n",
      "35\n",
      "predicted, actual 1 1.0\n",
      "36\n",
      "predicted, actual 1 1.0\n",
      "37\n",
      "predicted, actual 1 0.0\n",
      "38\n",
      "predicted, actual 0 0.0\n",
      "39\n",
      "predicted, actual 0 1.0\n",
      "40\n",
      "predicted, actual 1 1.0\n",
      "41\n",
      "predicted, actual 1 0.0\n",
      "42\n",
      "predicted, actual 1 1.0\n",
      "43\n",
      "predicted, actual 1 1.0\n",
      "44\n",
      "predicted, actual 1 1.0\n",
      "45\n",
      "predicted, actual 1 1.0\n",
      "46\n",
      "predicted, actual 1 1.0\n",
      "47\n",
      "predicted, actual 1 1.0\n",
      "48\n",
      "predicted, actual 1 1.0\n",
      "49\n",
      "predicted, actual 1 1.0\n",
      "50\n",
      "predicted, actual 1 1.0\n",
      "51\n",
      "predicted, actual 1 1.0\n",
      "52\n",
      "predicted, actual 1 1.0\n",
      "53\n",
      "predicted, actual 1 1.0\n",
      "54\n",
      "predicted, actual 0 0.0\n",
      "55\n",
      "predicted, actual 1 0.0\n",
      "56\n",
      "predicted, actual 1 0.0\n",
      "57\n",
      "predicted, actual 1 1.0\n",
      "58\n",
      "predicted, actual 1 0.0\n",
      "59\n",
      "predicted, actual 1 1.0\n",
      "60\n",
      "predicted, actual 1 0.0\n",
      "61\n",
      "predicted, actual 1 1.0\n",
      "62\n",
      "predicted, actual 1 1.0\n",
      "63\n",
      "predicted, actual 1 1.0\n",
      "64\n",
      "predicted, actual 1 1.0\n",
      "65\n",
      "predicted, actual 1 1.0\n",
      "66\n",
      "predicted, actual 1 0.0\n",
      "67\n",
      "predicted, actual 1 1.0\n",
      "68\n",
      "predicted, actual 1 0.0\n",
      "69\n",
      "predicted, actual 1 1.0\n",
      "70\n",
      "predicted, actual 1 1.0\n",
      "71\n",
      "predicted, actual 1 1.0\n",
      "72\n",
      "predicted, actual 1 1.0\n",
      "73\n",
      "predicted, actual 1 1.0\n",
      "74\n",
      "predicted, actual 1 1.0\n",
      "75\n",
      "predicted, actual 1 1.0\n",
      "76\n",
      "predicted, actual 1 1.0\n",
      "77\n",
      "predicted, actual 0 1.0\n",
      "78\n",
      "predicted, actual 0 0.0\n",
      "79\n",
      "predicted, actual 0 0.0\n",
      "80\n",
      "predicted, actual 0 1.0\n",
      "81\n",
      "predicted, actual 1 1.0\n",
      "82\n",
      "predicted, actual 1 1.0\n",
      "83\n",
      "predicted, actual 0 0.0\n",
      "84\n",
      "predicted, actual 1 1.0\n",
      "85\n",
      "predicted, actual 0 1.0\n",
      "86\n",
      "predicted, actual 1 1.0\n",
      "87\n",
      "predicted, actual 1 1.0\n",
      "88\n",
      "predicted, actual 1 0.0\n",
      "89\n",
      "predicted, actual 0 0.0\n",
      "90\n",
      "predicted, actual 1 1.0\n",
      "91\n",
      "predicted, actual 1 1.0\n",
      "92\n",
      "predicted, actual 1 0.0\n",
      "93\n",
      "predicted, actual 1 1.0\n",
      "94\n",
      "predicted, actual 0 1.0\n",
      "95\n",
      "predicted, actual 1 1.0\n",
      "96\n",
      "predicted, actual 1 1.0\n",
      "97\n",
      "predicted, actual 0 0.0\n",
      "98\n",
      "predicted, actual 1 1.0\n",
      "99\n",
      "predicted, actual 1 0.0\n",
      "100\n",
      "predicted, actual 0 1.0\n",
      "101\n",
      "predicted, actual 1 0.0\n",
      "102\n",
      "predicted, actual 1 1.0\n",
      "103\n",
      "predicted, actual 1 1.0\n",
      "104\n",
      "predicted, actual 1 0.0\n",
      "105\n",
      "predicted, actual 0 1.0\n",
      "106\n",
      "predicted, actual 1 1.0\n",
      "107\n",
      "predicted, actual 1 1.0\n",
      "108\n",
      "predicted, actual 1 1.0\n",
      "109\n",
      "predicted, actual 1 0.0\n",
      "110\n",
      "predicted, actual 1 0.0\n",
      "111\n",
      "predicted, actual 1 1.0\n",
      "112\n",
      "predicted, actual 1 1.0\n",
      "113\n",
      "predicted, actual 1 0.0\n",
      "114\n",
      "predicted, actual 1 0.0\n",
      "115\n",
      "predicted, actual 1 1.0\n",
      "116\n",
      "predicted, actual 1 1.0\n",
      "117\n",
      "predicted, actual 0 1.0\n",
      "118\n",
      "predicted, actual 1 1.0\n",
      "119\n",
      "predicted, actual 1 1.0\n",
      "120\n",
      "predicted, actual 1 1.0\n",
      "121\n",
      "predicted, actual 1 1.0\n",
      "122\n",
      "predicted, actual 1 1.0\n",
      "123\n",
      "predicted, actual 1 0.0\n",
      "124\n",
      "predicted, actual 0 1.0\n",
      "125\n",
      "predicted, actual 1 1.0\n",
      "126\n",
      "predicted, actual 1 1.0\n",
      "127\n",
      "predicted, actual 0 1.0\n",
      "128\n",
      "predicted, actual 1 1.0\n",
      "129\n",
      "predicted, actual 1 0.0\n",
      "130\n",
      "predicted, actual 1 0.0\n",
      "131\n",
      "predicted, actual 1 1.0\n",
      "132\n",
      "predicted, actual 1 1.0\n",
      "133\n",
      "predicted, actual 0 0.0\n",
      "134\n",
      "predicted, actual 1 0.0\n",
      "135\n",
      "predicted, actual 1 0.0\n",
      "136\n",
      "predicted, actual 1 1.0\n",
      "137\n",
      "predicted, actual 1 1.0\n",
      "138\n",
      "predicted, actual 1 1.0\n",
      "139\n",
      "predicted, actual 0 1.0\n",
      "140\n",
      "predicted, actual 0 1.0\n",
      "141\n",
      "predicted, actual 1 1.0\n",
      "142\n",
      "predicted, actual 0 0.0\n",
      "143\n",
      "predicted, actual 1 1.0\n",
      "144\n",
      "predicted, actual 1 0.0\n",
      "145\n",
      "predicted, actual 1 0.0\n",
      "146\n",
      "predicted, actual 0 1.0\n",
      "147\n",
      "predicted, actual 1 1.0\n",
      "148\n",
      "predicted, actual 0 0.0\n",
      "149\n",
      "predicted, actual 0 0.0\n",
      "150\n",
      "predicted, actual 1 0.0\n",
      "151\n",
      "predicted, actual 0 1.0\n",
      "152\n",
      "predicted, actual 1 1.0\n",
      "153\n",
      "predicted, actual 1 0.0\n",
      "154\n",
      "predicted, actual 1 0.0\n",
      "155\n",
      "predicted, actual 1 1.0\n",
      "156\n",
      "predicted, actual 1 1.0\n",
      "157\n",
      "predicted, actual 0 1.0\n",
      "158\n",
      "predicted, actual 1 1.0\n",
      "159\n",
      "predicted, actual 1 1.0\n",
      "160\n",
      "predicted, actual 1 1.0\n",
      "161\n",
      "predicted, actual 1 1.0\n",
      "162\n",
      "predicted, actual 1 1.0\n",
      "163\n",
      "predicted, actual 1 1.0\n",
      "164\n",
      "predicted, actual 1 1.0\n",
      "165\n",
      "predicted, actual 1 0.0\n",
      "166\n",
      "predicted, actual 0 1.0\n",
      "167\n",
      "predicted, actual 1 1.0\n",
      "168\n",
      "predicted, actual 1 1.0\n",
      "169\n",
      "predicted, actual 0 1.0\n",
      "170\n",
      "predicted, actual 1 1.0\n",
      "171\n",
      "predicted, actual 1 0.0\n",
      "172\n",
      "predicted, actual 0 1.0\n",
      "173\n",
      "predicted, actual 1 1.0\n",
      "174\n",
      "predicted, actual 1 1.0\n",
      "175\n",
      "predicted, actual 1 1.0\n",
      "176\n",
      "predicted, actual 1 1.0\n",
      "177\n",
      "predicted, actual 1 0.0\n",
      "178\n",
      "predicted, actual 1 1.0\n",
      "179\n",
      "predicted, actual 0 0.0\n",
      "180\n",
      "predicted, actual 1 1.0\n",
      "181\n",
      "predicted, actual 1 1.0\n",
      "182\n",
      "predicted, actual 1 0.0\n",
      "183\n",
      "predicted, actual 1 1.0\n",
      "184\n",
      "predicted, actual 1 1.0\n",
      "185\n",
      "predicted, actual 1 1.0\n",
      "186\n",
      "predicted, actual 1 0.0\n",
      "187\n",
      "predicted, actual 1 0.0\n",
      "188\n",
      "predicted, actual 1 0.0\n",
      "189\n",
      "predicted, actual 0 1.0\n",
      "190\n",
      "predicted, actual 0 0.0\n",
      "191\n",
      "predicted, actual 1 0.0\n",
      "192\n",
      "predicted, actual 1 1.0\n",
      "193\n",
      "predicted, actual 1 1.0\n",
      "194\n",
      "predicted, actual 0 0.0\n",
      "195\n",
      "predicted, actual 1 1.0\n",
      "196\n",
      "predicted, actual 1 1.0\n",
      "197\n",
      "predicted, actual 1 1.0\n",
      "198\n",
      "predicted, actual 1 1.0\n",
      "199\n",
      "total:  200\n",
      "correct:  138\n",
      "\n",
      "\n",
      "\n",
      "          Actual +ve  Actual -ve\n",
      "Pred +ve         122          41\n",
      "Pred -ve          20          16\n"
     ]
    }
   ],
   "source": [
    "correct, K = 0, 3\n",
    "\n",
    "\n",
    "count, tp, fp, tn, fn = 0, 0, 0, 0, 0\n",
    "\n",
    "\n",
    "for index, sample in test_set.iterrows():\n",
    "    print(count)\n",
    "    count +=1\n",
    "    if count == 200:\n",
    "        break\n",
    "    sample = pd.DataFrame(sample)\n",
    "    sample = sample.T\n",
    "\n",
    "    label = knn(train_set, sample, K)\n",
    "\n",
    "    if label == sample.iloc[0].values.tolist()[-1]:\n",
    "        correct += 1\n",
    "    \n",
    "    print('predicted, actual', label, sample.iloc[0].values.tolist()[-1])\n",
    "    if label == 1 and sample.iloc[0].values.tolist()[-1] == 1:\n",
    "        tp += 1\n",
    "    if label == 1 and sample.iloc[0].values.tolist()[-1] == 0:\n",
    "        fp += 1 \n",
    "    if label == 0 and sample.iloc[0].values.tolist()[-1] == 1:\n",
    "        fn += 1    \n",
    "    if label == 0 and sample.iloc[0].values.tolist()[-1] == 0:\n",
    "        tn += 1    \n",
    "        \n",
    "\n",
    "print('total: ', count)\n",
    "print('correct: ', correct)\n",
    "print('\\n\\n')\n",
    "\n",
    "matrix_list = np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "# matrix = pd.DataFrame({'Actual +ve': matrix_list[:, 0], 'Actual -ve': matrix_list[:, 1]})\n",
    "matrix = pd.DataFrame(matrix_list, index=['Pred +ve', 'Pred -ve'], columns=['Actual +ve', 'Actual -ve'])\n",
    "\n",
    "\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 26770\n",
      "Test set size: 50\n",
      "Correct predicitons: 39\n",
      "Accuracy: 78.00%\n",
      "precision:  0.8181818181818182\n",
      "recall:  0.9473684210526315\n",
      "fscore:  0.8780487804878049\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size: %d\" % len(train_set))\n",
    "print(\"Test set size: %d\" % count)\n",
    "print(\"Correct predicitons: %d\" % correct)\n",
    "print(\"Accuracy: %.2f%%\" % (100 * correct / count))\n",
    "\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "fscore = 2*((precision * recall)/(precision + recall))\n",
    "\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
