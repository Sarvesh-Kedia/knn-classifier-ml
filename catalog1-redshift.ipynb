{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('cat1.csv')\n",
    "\n",
    "\n",
    "# print(data.head())\n",
    "\n",
    "\n",
    "#features\n",
    "x = data.drop(['index', 'galex_objid', 'sdss_objid', 'class', 'pred'], axis = 1) \n",
    "# print(x.head())\n",
    "\n",
    "\n",
    "#class\n",
    "y = data['class']\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "#fix scientifci notations to normal floats\n",
    "# def scitofloat(x):\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     u    g    r    i    z  extinction_u  extinction_g  extinction_r  \\\n",
      "0  1.0  1.0  1.0  1.0  1.0      0.523712      0.518482      0.512789   \n",
      "1  1.0  1.0  1.0  1.0  1.0      0.526258      0.520468      0.514164   \n",
      "2  1.0  1.0  1.0  1.0  1.0      0.521345      0.516636      0.511511   \n",
      "3  1.0  1.0  1.0  1.0  1.0      0.518531      0.514442      0.509992   \n",
      "4  1.0  1.0  1.0  1.0  1.0      0.512538      0.509770      0.506759   \n",
      "\n",
      "   extinction_i  extinction_z  ...       g-z       r-i       r-z       i-z  \\\n",
      "0      0.509504      0.507070  ...  0.752323  0.573081  0.617067  0.545544   \n",
      "1      0.510526      0.507830  ...  0.937413  0.719195  0.797190  0.605481   \n",
      "2      0.508555      0.506363  ...  0.499443  0.537674  0.501030  0.463350   \n",
      "3      0.507426      0.505524  ...  0.591679  0.522131  0.574171  0.552384   \n",
      "4      0.505023      0.503736  ...  0.783204  0.636499  0.716019  0.590153   \n",
      "\n",
      "    fuv-nuv     fuv-u     fuv-g     fuv-r     fuv-i     fuv-z  \n",
      "0  0.107239  0.012509  0.003379  0.001796  0.001338  0.001115  \n",
      "1  0.408152  0.442483  0.190029  0.058001  0.023476  0.015423  \n",
      "2  0.243420  0.058497  0.054255  0.054582  0.047295  0.054370  \n",
      "3  0.279794  0.254533  0.229873  0.217371  0.202679  0.170804  \n",
      "4  0.305146  0.179948  0.093970  0.067501  0.039698  0.027908  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "#normalise the values of x\n",
    "\n",
    "outercnt = 0\n",
    "for index, row in x.iterrows():\n",
    "    innercnt = 0\n",
    "    for column in x:\n",
    "#         x.at[outercnt, column] = scitofloat(x.iloc[outercnt, innercnt])\n",
    "        x.at[outercnt, column] = sigmoid(x.iloc[outercnt, innercnt])\n",
    "#         print(outercnt, column, '\\t\\t', x.iloc[outercnt, innercnt])\n",
    "        innercnt += 1\n",
    "    outercnt += 1    \n",
    "\n",
    "#     print('\\n\\n')\n",
    "\n",
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_dataset(data, verbose=True):\n",
    "    label1, label2 = 0, 0\n",
    "    data_size = len(data)\n",
    "    for index, row in data.iterrows():\n",
    "        label = row['class']\n",
    "#         print(label)\n",
    "        if label == 1:\n",
    "            label1 += 1\n",
    "        else:\n",
    "            label2 += 1\n",
    "    if verbose:\n",
    "        print('Total of samples: %d' % data_size)\n",
    "        print('Total label 1: %d' % label1)\n",
    "        print('Total label 0: %d' % label2)\n",
    "    return [len(data), label1, label2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of samples: 649\n",
      "Total label 1: 595\n",
      "Total label 0: 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[649, 595, 54]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.6\n",
    "_, label1, label2 = info_dataset(data,False)\n",
    "\n",
    "info_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       u    g    r    i    z  extinction_u  extinction_g  extinction_r  \\\n",
      "425  1.0  1.0  1.0  1.0  1.0      0.514904      0.511614      0.508035   \n",
      "55   1.0  1.0  1.0  1.0  1.0      0.519491      0.515190      0.510510   \n",
      "512  1.0  1.0  1.0  1.0  1.0      0.511870      0.509250      0.506399   \n",
      "487  1.0  1.0  1.0  1.0  1.0      0.532910      0.525657      0.517758   \n",
      "\n",
      "     extinction_i  extinction_z  ...       r-i       r-z       i-z   fuv-nuv  \\\n",
      "425      0.505971      0.504442  ...  0.491625  0.548138  0.556422  0.299982   \n",
      "55       0.507811      0.505810  ...  0.522065  0.588425  0.566882  0.361392   \n",
      "512      0.504755      0.503537  ...  0.494274  0.446529  0.452196  0.418036   \n",
      "487      0.513198      0.509818  ...  0.501639  0.556020  0.554401  0.272535   \n",
      "\n",
      "        fuv-u     fuv-g     fuv-r     fuv-i     fuv-z  class  \n",
      "425  0.306498  0.246320  0.230738  0.236738  0.198245      1  \n",
      "55   0.152176  0.126272  0.122067  0.112914  0.088632      1  \n",
      "512  0.060764  0.037318  0.026722  0.027324  0.032911      1  \n",
      "487  0.189280  0.112959  0.110637  0.109994  0.090358      1  \n",
      "\n",
      "[4 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#get training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 15)\n",
    "\n",
    "train_set = pd.concat([xTrain, yTrain], axis=1, sort=False)\n",
    "test_set = pd.concat([xTest, yTest], axis=1, sort=False)\n",
    "\n",
    "\n",
    "print(train_set.iloc[0:4])\n",
    "# print(train_set.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(p1, p2):\n",
    "    dim, sum_ = len(p1), 0\n",
    "    for index in range(dim - 1):\n",
    "        sum_ += math.pow(p1[index] - p2[index], 2)\n",
    "    return math.sqrt(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_set, new_sample, K):\n",
    "\n",
    "#     print('train set', train_set, type(train_set))\n",
    "#     print('new sample', new_sample, type(new_sample))\n",
    "    dists, train_size = {}, len(train_set)\n",
    "\n",
    "    for i in range(train_size):\n",
    "#         print(train_set.iloc[i-1].values.tolist())\n",
    "#         print(new_sample.values.tolist()[0])\n",
    "#         print('\\n\\n')\n",
    "        d = euclidian_dist(train_set.iloc[i-1].values.tolist(), new_sample.values.tolist()[0])\n",
    "        dists[i] = d\n",
    "        \n",
    "#     print('done')\n",
    "    \n",
    "    k_neighbors = sorted(dists, key=dists.get)[:K]\n",
    "    \n",
    "    qty_label1, qty_label2 = 0, 0\n",
    "    \n",
    "    for index in k_neighbors:\n",
    "#         print('index, ', index)\n",
    "#         print(train_set.iloc[index])\n",
    "        \n",
    "    \n",
    "        if train_set.iloc[index].values.tolist()[-1] == 1:\n",
    "            qty_label1 += 1\n",
    "        else:\n",
    "            qty_label2 += 1\n",
    "        \n",
    "            \n",
    "    if qty_label1 > qty_label2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "predicted, actual 1 1.0\n",
      "1\n",
      "predicted, actual 0 1.0\n",
      "2\n",
      "predicted, actual 1 1.0\n",
      "3\n",
      "predicted, actual 1 1.0\n",
      "4\n",
      "predicted, actual 1 1.0\n",
      "5\n",
      "predicted, actual 1 1.0\n",
      "6\n",
      "predicted, actual 1 1.0\n",
      "7\n",
      "predicted, actual 1 1.0\n",
      "8\n",
      "predicted, actual 1 1.0\n",
      "9\n",
      "predicted, actual 1 1.0\n",
      "10\n",
      "predicted, actual 1 1.0\n",
      "11\n",
      "predicted, actual 1 1.0\n",
      "12\n",
      "predicted, actual 1 1.0\n",
      "13\n",
      "predicted, actual 1 1.0\n",
      "14\n",
      "predicted, actual 1 1.0\n",
      "15\n",
      "predicted, actual 1 1.0\n",
      "16\n",
      "predicted, actual 1 1.0\n",
      "17\n",
      "predicted, actual 1 0.0\n",
      "18\n",
      "predicted, actual 1 1.0\n",
      "19\n",
      "predicted, actual 1 1.0\n",
      "20\n",
      "predicted, actual 1 1.0\n",
      "21\n",
      "predicted, actual 1 1.0\n",
      "22\n",
      "predicted, actual 1 1.0\n",
      "23\n",
      "predicted, actual 1 1.0\n",
      "24\n",
      "predicted, actual 1 1.0\n",
      "25\n",
      "predicted, actual 1 1.0\n",
      "26\n",
      "predicted, actual 1 1.0\n",
      "27\n",
      "predicted, actual 1 0.0\n",
      "28\n",
      "predicted, actual 1 1.0\n",
      "29\n",
      "predicted, actual 1 1.0\n",
      "30\n",
      "predicted, actual 1 1.0\n",
      "31\n",
      "predicted, actual 1 1.0\n",
      "32\n",
      "predicted, actual 1 1.0\n",
      "33\n",
      "predicted, actual 1 1.0\n",
      "34\n",
      "predicted, actual 1 1.0\n",
      "35\n",
      "predicted, actual 1 1.0\n",
      "36\n",
      "predicted, actual 1 1.0\n",
      "37\n",
      "predicted, actual 1 1.0\n",
      "38\n",
      "predicted, actual 1 1.0\n",
      "39\n",
      "predicted, actual 1 1.0\n",
      "40\n",
      "predicted, actual 1 0.0\n",
      "41\n",
      "predicted, actual 1 1.0\n",
      "42\n",
      "predicted, actual 1 1.0\n",
      "43\n",
      "predicted, actual 1 1.0\n",
      "44\n",
      "predicted, actual 1 1.0\n",
      "45\n",
      "predicted, actual 1 1.0\n",
      "46\n",
      "predicted, actual 1 1.0\n",
      "47\n",
      "predicted, actual 1 1.0\n",
      "48\n",
      "predicted, actual 1 1.0\n",
      "49\n",
      "predicted, actual 1 1.0\n",
      "50\n",
      "predicted, actual 1 1.0\n",
      "51\n",
      "predicted, actual 1 1.0\n",
      "52\n",
      "predicted, actual 1 1.0\n",
      "53\n",
      "predicted, actual 1 1.0\n",
      "54\n",
      "predicted, actual 1 1.0\n",
      "55\n",
      "predicted, actual 1 1.0\n",
      "56\n",
      "predicted, actual 1 1.0\n",
      "57\n",
      "predicted, actual 1 1.0\n",
      "58\n",
      "predicted, actual 1 1.0\n",
      "59\n",
      "predicted, actual 1 1.0\n",
      "60\n",
      "predicted, actual 1 1.0\n",
      "61\n",
      "predicted, actual 1 1.0\n",
      "62\n",
      "predicted, actual 1 1.0\n",
      "63\n",
      "predicted, actual 1 1.0\n",
      "64\n",
      "predicted, actual 1 1.0\n",
      "65\n",
      "predicted, actual 1 1.0\n",
      "66\n",
      "predicted, actual 1 1.0\n",
      "67\n",
      "predicted, actual 1 1.0\n",
      "68\n",
      "predicted, actual 1 1.0\n",
      "69\n",
      "predicted, actual 1 1.0\n",
      "70\n",
      "predicted, actual 1 1.0\n",
      "71\n",
      "predicted, actual 1 1.0\n",
      "72\n",
      "predicted, actual 1 0.0\n",
      "73\n",
      "predicted, actual 1 1.0\n",
      "74\n",
      "predicted, actual 1 1.0\n",
      "75\n",
      "predicted, actual 1 0.0\n",
      "76\n",
      "predicted, actual 1 1.0\n",
      "77\n",
      "predicted, actual 1 1.0\n",
      "78\n",
      "predicted, actual 1 1.0\n",
      "79\n",
      "predicted, actual 1 1.0\n",
      "80\n",
      "predicted, actual 1 1.0\n",
      "81\n",
      "predicted, actual 1 0.0\n",
      "82\n",
      "predicted, actual 1 1.0\n",
      "83\n",
      "predicted, actual 1 1.0\n",
      "84\n",
      "predicted, actual 1 1.0\n",
      "85\n",
      "predicted, actual 1 1.0\n",
      "86\n",
      "predicted, actual 0 1.0\n",
      "87\n",
      "predicted, actual 1 1.0\n",
      "88\n",
      "predicted, actual 1 0.0\n",
      "89\n",
      "predicted, actual 1 1.0\n",
      "90\n",
      "predicted, actual 1 1.0\n",
      "91\n",
      "predicted, actual 1 1.0\n",
      "92\n",
      "predicted, actual 1 1.0\n",
      "93\n",
      "predicted, actual 1 0.0\n",
      "94\n",
      "predicted, actual 1 1.0\n",
      "95\n",
      "predicted, actual 1 1.0\n",
      "96\n",
      "predicted, actual 1 1.0\n",
      "97\n",
      "predicted, actual 1 0.0\n",
      "98\n",
      "predicted, actual 1 1.0\n",
      "99\n",
      "predicted, actual 1 1.0\n",
      "100\n",
      "predicted, actual 1 1.0\n",
      "101\n",
      "predicted, actual 1 1.0\n",
      "102\n",
      "predicted, actual 1 1.0\n",
      "103\n",
      "predicted, actual 1 1.0\n",
      "104\n",
      "predicted, actual 1 1.0\n",
      "105\n",
      "predicted, actual 1 1.0\n",
      "106\n",
      "predicted, actual 1 1.0\n",
      "107\n",
      "predicted, actual 0 1.0\n",
      "108\n",
      "predicted, actual 1 1.0\n",
      "109\n",
      "predicted, actual 1 1.0\n",
      "110\n",
      "predicted, actual 1 1.0\n",
      "111\n",
      "predicted, actual 1 1.0\n",
      "112\n",
      "predicted, actual 1 1.0\n",
      "113\n",
      "predicted, actual 1 1.0\n",
      "114\n",
      "predicted, actual 1 1.0\n",
      "115\n",
      "predicted, actual 1 1.0\n",
      "116\n",
      "predicted, actual 1 1.0\n",
      "117\n",
      "predicted, actual 1 1.0\n",
      "118\n",
      "predicted, actual 1 1.0\n",
      "119\n",
      "predicted, actual 1 1.0\n",
      "120\n",
      "predicted, actual 1 1.0\n",
      "121\n",
      "predicted, actual 1 1.0\n",
      "122\n",
      "predicted, actual 1 1.0\n",
      "123\n",
      "predicted, actual 1 1.0\n",
      "124\n",
      "predicted, actual 1 1.0\n",
      "125\n",
      "predicted, actual 1 1.0\n",
      "126\n",
      "predicted, actual 1 1.0\n",
      "127\n",
      "predicted, actual 1 0.0\n",
      "128\n",
      "predicted, actual 1 1.0\n",
      "129\n",
      "predicted, actual 1 0.0\n",
      "total:  130\n",
      "correct:  116\n",
      "\n",
      "\n",
      "\n",
      "          Actual +ve  Actual -ve\n",
      "Pred +ve         116          11\n",
      "Pred -ve           3           0\n"
     ]
    }
   ],
   "source": [
    "correct, K = 0, 3\n",
    "\n",
    "count, tp, fp, tn, fn = 0, 0, 0, 0, 0\n",
    "\n",
    "\n",
    "for index, sample in test_set.iterrows():\n",
    "    print(count)\n",
    "    count +=1\n",
    "    sample = pd.DataFrame(sample)\n",
    "    sample = sample.T\n",
    "\n",
    "    label = knn(train_set, sample, K)\n",
    "\n",
    "    if label == sample.iloc[0].values.tolist()[-1]:\n",
    "        correct += 1\n",
    "    \n",
    "    print('predicted, actual', label, sample.iloc[0].values.tolist()[-1])\n",
    "    if label == 1 and sample.iloc[0].values.tolist()[-1] == 1:\n",
    "        tp += 1\n",
    "    if label == 1 and sample.iloc[0].values.tolist()[-1] == 0:\n",
    "        fp += 1 \n",
    "    if label == 0 and sample.iloc[0].values.tolist()[-1] == 1:\n",
    "        fn += 1    \n",
    "    if label == 0 and sample.iloc[0].values.tolist()[-1] == 0:\n",
    "        tn += 1    \n",
    "\n",
    "print('total: ', count)\n",
    "print('correct: ', correct)\n",
    "print('\\n\\n')\n",
    "\n",
    "matrix_list = np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "# matrix = pd.DataFrame({'Actual +ve': matrix_list[:, 0], 'Actual -ve': matrix_list[:, 1]})\n",
    "matrix = pd.DataFrame(matrix_list, index=['Pred +ve', 'Pred -ve'], columns=['Actual +ve', 'Actual -ve'])\n",
    "\n",
    "\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 519\n",
      "Test set size: 130\n",
      "Correct predicitons: 116\n",
      "Accuracy: 89.23%\n",
      "precision:  0.9133858267716536\n",
      "recall:  0.9747899159663865\n",
      "fscore:  0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size: %d\" % len(train_set))\n",
    "print(\"Test set size: %d\" % len(test_set))\n",
    "print(\"Correct predicitons: %d\" % correct)\n",
    "print(\"Accuracy: %.2f%%\" % (100 * correct / len(test_set)))\n",
    "\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "fscore = 2*((precision * recall)/(precision + recall))\n",
    "\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('fscore: ', fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
